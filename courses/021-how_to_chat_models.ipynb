{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to: Chat models\n",
    "\n",
    "Resource: https://python.langchain.com/docs/how_to/#chat-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from custom_features.models import MODELS\n",
    "from custom_features.params_setting_fct import set_api_keys, set_langsmith\n",
    "\n",
    "set_api_keys()\n",
    "set_langsmith()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use chat models to call tools\n",
    "\n",
    "Resource: https://python.langchain.com/docs/how_to/tool_calling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_mistralai.chat_models import ChatMistralAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(parse_docstring=True, response_format=\"content_and_artifact\")\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two integers.\n",
    "\n",
    "    Args:\n",
    "        a: First integer\n",
    "        b: Second integer\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool(parse_docstring=True, response_format=\"content_and_artifact\")\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two integers.\n",
    "\n",
    "    Args:\n",
    "        a: First integer\n",
    "        b: Second integer\n",
    "    \"\"\"\n",
    "    return a * b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class add(BaseModel):\n",
    "    \"\"\"Add two integers.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "\n",
    "class multiply(BaseModel):\n",
    "    \"\"\"Multiply two integers.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatMistralAI(model_name=MODELS[0][\"model\"], max_retries=5)\n",
    "llm = ChatMistralAI(model_name=\"mistral-large-latest\", max_retries=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools([add, multiply])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is 3 + 12?\"\n",
    "\n",
    "llm_with_tools.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is 3 * 12? And, what is 11 + 49?\"\n",
    "\n",
    "called_tools = llm_with_tools.invoke(query)\n",
    "\n",
    "print(called_tools.tool_calls)\n",
    "print(called_tools.invalid_tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import PydanticToolsParser\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class add(BaseModel):\n",
    "    \"\"\"Add two integers.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "\n",
    "class multiply(BaseModel):\n",
    "    \"\"\"Multiply two integers.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools([add, multiply])\n",
    "\n",
    "chain = llm_with_tools | PydanticToolsParser(tools=[add, multiply])\n",
    "chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import StructuredTool\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.tools import ToolException\n",
    "\n",
    "\n",
    "class CalculatorInput(BaseModel):\n",
    "    a: int = Field(description=\"first number\")\n",
    "    b: int = Field(description=\"second number\")\n",
    "\n",
    "\n",
    "def add_integers(a: int, b: int) -> str:\n",
    "    \"\"\"Add two integers.\"\"\"\n",
    "    return f\"{a + b}\"\n",
    "\n",
    "\n",
    "def multiply_integers(a: int, b: int) -> str:\n",
    "    \"\"\"Multiply two integers.\"\"\"\n",
    "    return a * b\n",
    "    # content = a * b\n",
    "    # if content <= 20:\n",
    "    #     return content\n",
    "    # else:\n",
    "    #     raise ToolException(f\"multiplication should be superior or equal to '20'. Found '{content}'\")\n",
    "\n",
    "add_calculator = StructuredTool.from_function(func=add_integers,\n",
    "                                              name=\"Addition\",\n",
    "                                              description=\"add integers\",\n",
    "                                              args_schema=CalculatorInput,\n",
    "                                              return_direct=False,  # default is False\n",
    "                                              handle_tool_error=True)\n",
    "\n",
    "multiply_calculator = StructuredTool.from_function(func=multiply_integers,\n",
    "                                                   name=\"Multiply\",\n",
    "                                                   description=\"multiply integers\",\n",
    "                                                   args_schema=CalculatorInput,\n",
    "                                                   return_direct=False,  # default is False\n",
    "                                                   response_format=\"content\",\n",
    "                                                   handle_tool_error=True)\n",
    "\n",
    "llm_with_tools_errors_handling = llm.bind_tools([add_calculator, multiply_calculator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_test = \"What 3 * 6?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools_errors_handling.invoke(query_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_calculator.invoke({\"a\": 4, \"b\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiply_calculator.invoke({\"name\": \"mulitply_calculator\",\n",
    "                            \"args\": {\"a\": 3, \"b\": 7},\n",
    "                            \"id\": \"123\",\n",
    "                            \"type\": \"tool_call\"}\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiply_calculator.invoke({\"a\": 3, \"b\": 7})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to pass tool outputs to chat models\n",
    "\n",
    "Resource: https://python.langchain.com/docs/how_to/tool_results_pass_to_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mistralai import ChatMistralAI\n",
    "\n",
    "llm = ChatMistralAI(model_name=MODELS[0][\"model\"], max_retries=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [add, multiply]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is 41 + 74? Also, what is 3 * 49?\"\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_msg.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(ai_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply}[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to return structured data from a model\n",
    "\n",
    "Resource: https://python.langchain.com/docs/how_to/structured_output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMistralAI(client=<httpx.Client object at 0x00000213EC56C130>, async_client=<httpx.AsyncClient object at 0x00000213EE6BFBB0>, mistral_api_key=SecretStr('**********'), endpoint='https://api.mistral.ai/v1', model='open-mistral-7b')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_mistralai import ChatMistralAI\n",
    "\n",
    "llm = ChatMistralAI(model_name=MODELS[0][\"model\"], max_retries=5)\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pydantic structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Joke(BaseModel):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline of the joke\")\n",
    "    rating: Optional[int] = Field(default=None,\n",
    "                                  description=\"How funny the joke is, from 1 to 10\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UselessKnowledge(BaseModel):\n",
    "    \"\"\"Teach a useless knowledge to shine in society.\"\"\"\n",
    "\n",
    "    knowledge: str = Field(description=\"The useless knowledge to teach\")\n",
    "    rating: Optional[int] = Field(default=None,\n",
    "                                  description=(\"How useless the knowledge is, \"\n",
    "                                               \"from 1 (very useful) to 10 (very useless)\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm = llm.with_structured_output(Joke)\n",
    "structured_llm = llm.with_structured_output(UselessKnowledge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UselessKnowledge(knowledge=\"Did you know that a group of flamingos is called a 'flamboyance'?\", rating=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llm.invoke(\"Hello, I'd like to learn something\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TypedDict structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON Schema structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
