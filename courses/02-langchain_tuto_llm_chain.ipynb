{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Chain tutorial\n",
    "\n",
    "Resource: https://python.langchain.com/docs/tutorials/llm_chain/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from custom_features.models import MODELS\n",
    "from custom_features.params_setting_fct import set_api_keys, set_langsmith\n",
    "\n",
    "set_api_keys()\n",
    "set_langsmith()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MODELS[0][\"model\"]\n",
    "model_provider=MODELS[0][\"model_provider\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model(model=model, model_provider=model_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ciao! (pronounced \"chiao\") This is a common greeting in Italian, equivalent to \"hi\" in English.', additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 13, 'total_tokens': 41, 'completion_tokens': 28}, 'model': 'open-mistral-7b', 'finish_reason': 'stop'}, id='run-fc8c34a1-345b-44b1-ba45-1880fda9a78d-0', usage_metadata={'input_tokens': 13, 'output_tokens': 28, 'total_tokens': 41})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following into Italian\"),\n",
    "    HumanMessage(\"hi!\"),\n",
    "]\n",
    "\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello there! How can I assist you today? I'm here to help answer any questions you have or to engage in a friendly conversation. What would you like to talk about?\", additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 4, 'total_tokens': 41, 'completion_tokens': 37}, 'model': 'open-mistral-7b', 'finish_reason': 'stop'}, id='run-21626e49-baca-4b75-b834-dfb38dceb35f-0', usage_metadata={'input_tokens': 4, 'output_tokens': 37, 'total_tokens': 41})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hello\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello there! How can I help you today? I'm here to answer any questions you have or to chat about any topic you'd like. What's on your mind?\", additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 4, 'total_tokens': 42, 'completion_tokens': 38}, 'model': 'open-mistral-7b', 'finish_reason': 'stop'}, id='run-1c3d0b9c-45a4-4138-9684-4e2ff7057cfa-0', usage_metadata={'input_tokens': 4, 'output_tokens': 38, 'total_tokens': 42})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "llm.invoke([{\"role\": \"user\", \"content\": \"Hello\"}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! How can I help you today? I'm here to answer any questions you have about AI, data science, programming, or any other topic you're interested in. Just let me know what you'd like to know, and I'll do my best to assist you. Is there a specific topic you have in mind, or would you like to know more about AI in general? I'm looking forward to chatting with you!\", additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 4, 'total_tokens': 97, 'completion_tokens': 93}, 'model': 'open-mistral-7b', 'finish_reason': 'stop'}, id='run-35bac415-5c47-49dd-82eb-3b208cefedfd-0', usage_metadata={'input_tokens': 4, 'output_tokens': 93, 'total_tokens': 97})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "llm.invoke([HumanMessage(\"Hello\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|C|iao|!| (|Hi| in| Italian|)||"
     ]
    }
   ],
   "source": [
    "for token in llm.stream(messages):\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"Translate the following from English into {language}\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_template),\n",
    "        (\"user\", \"{text}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following from English into Japanese', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.invoke({\"language\": \"Japanese\", \"text\": \"Hi!\"})\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは！(Konnichiwa!)\n",
      "\n",
      "This is a common greeting in Japanese, which can be used during the day. It's similar to saying \"Hello\" in English.\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(prompt)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
